{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "<img src=\"./imgs/DRRlogo.jpg\" width=\"350\" />\n",
    "\n",
    "# Land Cover Classification for use in the CAPRA Model \n",
    "\n",
    "## Derivation of Additional Information \n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "In this lesson you will learn how to implement spectral indices and textural features that can be used to enhance phenomena of interest in remotely sensed images. \n",
    "\n",
    "\n",
    "### Spectral Indices\n",
    "\n",
    "Spectral indices are based on the fact that reflectance spectra of different land covers are different. The indices are designed to exploit these differences to accentuate particular land cover types. Consider the following chart  of reflectance spectra for various targets:\n",
    "\n",
    "<img src=\"./imgs/Spectral_Indices.PNG\">\n",
    "\n",
    "\n",
    "Observe that the land covers are separable at one or more wavelengths. Note, in particular, that vegetation curves have relatively high reflectance in the near-infrared (NIR) range, where radiant energy is scattered by cell walls. Also note that vegetation has low reflectance in the red range, where radiant energy is absorbed by chlorophyll. These observations motivate the formulation of vegetaion indices. \n",
    "\n",
    "Extracting spectral or spatial information is not a uncommon task during processing remotely sensed images because these information may improve classification results capturing additional information than spectral bands. <br>\n",
    "\n",
    "Indices combine data from two or more spectral bands to accentuate land formation features.  Several Vegetation Indices (VIs) have been derived for Landsat data (Jensen, 2005). These indices are intended to enhance the vegetation signal, while minimizing any background effects or noise.  VIs can be calculated from brightness values (BVs), radiance values (Lλ) and reflectance values (ρp).  If vegetation transformations or indices are going to be used in spectral extraction for land cover classification purposes it is recommended to use reflectance values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Difference Vegetation Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normalized Difference Vegetation Index (NDVI) is a quick and accurate way of analyzing vegetation in an image.  This calculation takes advantage of the fact that vegetation is very absorbent in the red band and very reflective in the NIR.  Therefore, surfaces with large amounts of vegetation can be found by comparing the ratio of red and NIR bands.\n",
    "\n",
    "The output of NDVI is a new grid layer.  Higher values (above zero) signify a larger difference between the red and near infrared radiation recorded by the sensor - a condition associated with highly photosynthetically-active vegetation. Low NDVI values (less than zero) mean there is little difference between the red and NIR signals.  This is an indicator for presence of little photosynthetic activity, or when there is just very low NIR light reflectance (i.e., water reflects very low NIR light).\n",
    "\n",
    "Google Earth Engine (GEE) has implemented a *normalizedDifference* function to compute the normalized difference between two bands. This function is used to compute the normalized vegetation index - [NDVI] (https://en.wikipedia.org/wiki/Normalized_Difference_Vegetation_Index). Given *B4* and  *B5*.\n",
    "\n",
    "The normalized difference vegetation index ($NDVI$) is a band ratio that is related to the amount of green vegetation. \n",
    "\n",
    "\\begin{equation*}\n",
    "NDVI = \\frac{NIR — RED}{NIR + RED} = \\frac{Band5 — Band4}{Band5 + Band4}\n",
    "\\end{equation*}\n",
    "\n",
    "where $NIR$ is the near infrared band and $RED$ is red band.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import ee\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import cm, colorbar\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "# Initialize the Earth Engine object, using the authentication credentials.\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bands': [{'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 32767,\n",
      "                          'min': -32768,\n",
      "                          'precision': 'int',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B1'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 32767,\n",
      "                          'min': -32768,\n",
      "                          'precision': 'int',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B2'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 32767,\n",
      "                          'min': -32768,\n",
      "                          'precision': 'int',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B3'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 32767,\n",
      "                          'min': -32768,\n",
      "                          'precision': 'int',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B4'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 32767,\n",
      "                          'min': -32768,\n",
      "                          'precision': 'int',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B5'}],\n",
      " 'type': 'Image'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=347c79bb53b37d5a6be04bbf43646cf5&token=a395bb5e309cfff42aaad317b32d25f5\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data\n",
    "area_of_interest = ee.Geometry.Rectangle([-70.81, 19.76, -69.27, 18.44])\n",
    "landsat8_collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterDate('2018-01-01', '2018-04-19').min()\n",
    "landsat8_collection = landsat8_collection.slice(0,5)\n",
    "pprint.pprint(landsat8_collection.getInfo())\n",
    "\n",
    "image = landsat8_collection.clip(area_of_interest)\n",
    "theGeom = area_of_interest.getInfo()['coordinates']\n",
    "thumbnail = image.getThumbUrl({'min':0,'max':2048,'size':'800', 'bands': 'B4,B3,B2', 'region':theGeom})\n",
    "Image(url=thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=5311e551f3f4b3eca4a2ad7edc58aa16&token=84ad96ce085a944049df7393a5c7c708\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the normalized vegetation index using Infrared and red bands\n",
    "# NDVI = (NIR - red) / (NIR + red)\n",
    "\n",
    "# Functions to derive vegetation indices and other raster operations\n",
    "def NDVI(image):\n",
    "    return image.normalizedDifference(['B5', 'B4'])\n",
    "\n",
    "ndvi = NDVI(landsat8_collection)\n",
    "\n",
    "#Display thumbnail of NDVI output\n",
    "image_ndvi = ndvi.clip(area_of_interest)\n",
    "theGeom = area_of_interest.getInfo()['coordinates']\n",
    "#thumbnail = image_ndvi.getThumbUrl({'min':-1,'max':1,'size':'800'})\n",
    "#Image(url=thumbnail)\n",
    "\n",
    "clas_col = ','.join(['d7191c','fdae61','ffffbf','a6d96a','1a9641'])\n",
    "Image(url = image_ndvi.getThumbUrl({'min': -1, 'max': 1, 'palette':clas_col}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Questions:<br> (1)Examine the values in vegetated and water areas in the NDVI image. Where is the NDVI image darkest, why?<br>  (2)\tIf you were a farmer would you want a high or a low NDVI for your fields?<br>  \n",
    "\n",
    "Other vegetation indices may involve additional computation rather than a normalized difference.<br>\n",
    "For those cases, GEE includes the *expression* function. The following example calculates the *Enhanced Vegetation Index - EVI*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Vegetation Index\n",
    "\n",
    "The Enhanced Vegetation Index (EVI) is designed to minimize saturation and background effects in NDVI. Since it is not a normalized difference index, we can compute it with the following expression:\n",
    "\n",
    "\\begin{equation*}\n",
    "EVI = \\frac{NIR — RED}{NIR + C1 * RED - C2 * BLUE + L} =  \\frac{Band5 — Band4}{Band5 + C1 * Band4 - C2 * Band2 + L}\n",
    "\\end{equation*}\n",
    "\n",
    "Where L is the canopy background adjustment that addresses non-linear, differential NIR and red radiant transfer through a canopy, and C1, C2 are the coefficients of the aerosol resistance term, which uses the blue band to correct for aerosol influences in the red band. The coefficients adopted in the Landsat 8 (OLI) algorithm are; L=1, C1 = 6, C2 = 7.5, and G (gain factor) = 2.5. \n",
    "\n",
    "Whereas the NDVI is chlorophyll sensitive, the EVI is more responsive to canopy structural variations, including leaf area index (LAI), canopy type, plant physiognomy, and canopy architecture. The two vegetation indices complement each other in global vegetation studies and improve upon the detection of vegetation changes and extraction of canopy biophysical parameters.\n",
    "\n",
    "Another difference between Normalized Difference Vegetation Index (NDVI) and EVI is that in the presence of snow, NDVI decreases, while EVI increases (Huete, 2002)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=20fa636dcab440a4243ddca63cfbee64&token=a6853ba0744115acb272c39a998371f9\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Enhanced Vegetation Index\n",
    "def EVI(image):\n",
    "    # L(Canopy background)\n",
    "    # C1,C2(Coefficients of aerosol resistance term)\n",
    "    # GainFactor(Gain or scaling factor)\n",
    "    gain_factor = ee.Image(2.5);\n",
    "    coefficient_1 = ee.Image(6);\n",
    "    coefficient_2 = ee.Image(7.5);\n",
    "    l = ee.Image(1);\n",
    "    nir = image.select(\"B5\");\n",
    "    red = image.select(\"B4\");\n",
    "    blue = image.select(\"B2\");\n",
    "    evi = image.expression(\n",
    "        \"Gain_Factor*((NIR-RED)/(NIR+C1*RED-C2*BLUE+L))\",\n",
    "        {\n",
    "            \"Gain_Factor\":gain_factor,\n",
    "            \"NIR\":nir,\n",
    "            \"RED\":red,\n",
    "            \"C1\":coefficient_1,\n",
    "            \"C2\":coefficient_2,\n",
    "            \"BLUE\":blue,\n",
    "            \"L\":l\n",
    "        }\n",
    "    )\n",
    "    return evi\n",
    "\n",
    "evi = EVI(landsat8_collection)\n",
    "\n",
    "#Display thumbnail of classification output\n",
    "image_evi = evi.clip(area_of_interest)\n",
    "theGeom = area_of_interest.getInfo()['coordinates']\n",
    "#thumbnail = image_evi.getThumbUrl({'min':-1,'max':1,'size':'800','region':theGeom})\n",
    "#Image(url=thumbnail)\n",
    "\n",
    "clas_col = ','.join(['d7191c','fdae61','ffffbf','a6d96a','1a9641'])\n",
    "Image(url = image_evi.getThumbUrl({'min': -1, 'max': 1, 'palette':clas_col}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Difference Water Index\n",
    "\n",
    "The Normalized Difference Water Index (NDWI) was developed by Gao (1996) as an index of vegetation water content:\n",
    "\n",
    "\\begin{equation*}\n",
    "NDWI = \\frac{NIR — SWIR}{NIR + SWIR} = \\frac{Band5 — Band3}{Band5 + Band3}\n",
    "\\end{equation*}\n",
    "\n",
    "Note that this is not an exact implementation of NDWI according to the Landsat 8 Operational Land Imager (OLI) spectral response, since the OLI does not have a band in the right position (1.26 um)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may try to compute the *NDWI*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textural Features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a small area in an image has a wide variation of shades of gray, the dominant property of that area is texture. Textural features provide information about the spatial distribution of the spectral information in an image band. Textural features may be not intuitive to the human eye but several studies have showed their contribution in image classification. Texture can be incorporated into a classification process by creating a new texture image that can be used as another feature. Each pixel in the new image has a brightness value that represents the texture at that location. <br> \n",
    "\n",
    "We will use the image.reduceNeighborhood() function to apply a reducer using a sliding window over the input image. The window size and shape will be specified by the ee.kernel function (tutorial 4). The output will be another image (in our case bands 1 to 5), with each new pixel representing the output of the reduction in a neighborhood around that pixel in the input image. \n",
    "\n",
    "We will select a square kernel that has the following parameters: <br>\n",
    "+ *radius (Float)* :  The radius of the kernel to generate. For a 3x3 kernel, we should use 1, for 5x5 kernel we should use 2 and so on. <br>\n",
    "+ *units (String) *:The system of measurement for the kernel \"meters\" or \"pixels\". Default value: \"pixels\".<br>\n",
    "+ *normalize (Boolean)*: Indicates if the kernel values should be normalized to sum 1. Default value: \"True\".<br>\n",
    "+ *magnitude (Float) *: Scale each value by this amount. Default: 1.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meanB1' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-78c858c336ee>\"\u001b[1;36m, line \u001b[1;32m8\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    pprint.pprint(meanB1.getInfo())\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'meanB1' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Define the kernel\n",
    "kernel = ee.Kernel.square(1, 'pixels')  # filter mean of 3*3\n",
    "# Compue mean as texture of the landsat 8 collection\n",
    "mean = landsat8_collection.reduceNeighborhood(\n",
    "    ee.Reducer.mean(),\n",
    "    kernel\n",
    ")\n",
    "pprint.pprint(meanB1.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualize textural features </b>\n",
    "\n",
    "Minimun and maximum values of each band must be explored to set the visualization parameters.<br>\n",
    "To find those values we will apply a <i>reducer</i> over the whole image. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'min', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -32768.0, 'max': 32767.0}, 'crs': 'EPSG:4326', 'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, {'id': 'max', 'data_type': {'type': 'PixelType', 'precision': 'double', 'min': -32768.0, 'max': 32767.0}, 'crs': 'EPSG:4326', 'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}]}\n"
     ]
    }
   ],
   "source": [
    "# Compute min and max of any band \n",
    "print(mean.select('B2_mean').reduce(ee.Reducer.minMax()).getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=2a653ebb935262574db43e6b702f2f62&token=acc1b62a6d455c0f6fd1dbacda5a1488\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbnail = landsat8_collection.select('B2').getThumbUrl({'min':0,'max':2000,'size':'800','region':theGeom})\n",
    "Image(url=thumbnail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://earthengine.googleapis.com/api/thumb?thumbid=283b48e63e999cade2fee4a11b28ab97&token=7fc8b6c5a455374940fc92873f56bf78\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thumbnail = mean.select('B2_mean').getThumbUrl({'min':0,'max':2048,'size':'800','region':theGeom})\n",
    "Image(url=thumbnail)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
